<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="UTF-8">
<meta name="viewport" content="width=device-width">
<meta name="theme-color" content="#222"><meta name="generator" content="Hexo 6.3.0">


  <link rel="apple-touch-icon" sizes="180x180" href="/images/avatar.png">
  <link rel="icon" type="image/png" sizes="32x32" href="/images/favicon-32x32-next.png">
  <link rel="icon" type="image/png" sizes="16x16" href="/images/favicon-16x16-next.png">
  <link rel="mask-icon" href="/images/logo.svg" color="#222">

<link rel="stylesheet" href="/css/main.css">



<link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.2.0/css/all.min.css" integrity="sha256-AbA177XfpSnFEvgpYu1jMygiLabzPCJCRIBtR5jGc0k=" crossorigin="anonymous">
  <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/animate.css/3.1.1/animate.min.css" integrity="sha256-PR7ttpcvz8qrF57fur/yAx1qXMFJeJFiA6pSzWi0OIE=" crossorigin="anonymous">

<script class="next-config" data-name="main" type="application/json">{"hostname":"example.com","root":"/","images":"/images","scheme":"Muse","darkmode":false,"version":"8.13.0","exturl":false,"sidebar":{"position":"left","display":"post","padding":18,"offset":12},"copycode":{"enable":false,"style":null},"bookmark":{"enable":false,"color":"#222","save":"auto"},"mediumzoom":false,"lazyload":false,"pangu":false,"comments":{"style":"tabs","active":null,"storage":true,"lazyload":false,"nav":null},"stickytabs":false,"motion":{"enable":true,"async":false,"transition":{"post_block":"fadeIn","post_header":"fadeInDown","post_body":"fadeInDown","coll_header":"fadeInLeft","sidebar":"fadeInUp"}},"prism":false,"i18n":{"placeholder":"Searching...","empty":"We didn't find any results for the search: ${query}","hits_time":"${hits} results found in ${time} ms","hits":"${hits} results found"}}</script><script src="/js/config.js"></script>

    <meta name="description" content="概述 有一个独立模块来生成区域建议的网络被称为两阶段检测器。">
<meta property="og:type" content="article">
<meta property="og:title" content="双阶段物体检测">
<meta property="og:url" content="http://example.com/2022/10/26/%E5%8F%8C%E9%98%B6%E6%AE%B5%E7%89%A9%E4%BD%93%E6%A3%80%E6%B5%8B/index.html">
<meta property="og:site_name" content="Scofield">
<meta property="og:description" content="概述 有一个独立模块来生成区域建议的网络被称为两阶段检测器。">
<meta property="og:locale" content="en_US">
<meta property="og:image" content="http://example.com/2022/10/26/%E5%8F%8C%E9%98%B6%E6%AE%B5%E7%89%A9%E4%BD%93%E6%A3%80%E6%B5%8B/RCNN.png">
<meta property="og:image" content="https://www.mihaileric.com/static/vector_through_svm_classifiers-cc139d6728db3205c0297a8f04c010ee-6fd10.png">
<meta property="og:image" content="http://example.com/2022/10/26/%E5%8F%8C%E9%98%B6%E6%AE%B5%E7%89%A9%E4%BD%93%E6%A3%80%E6%B5%8B/SPP.png">
<meta property="og:image" content="https://miro.medium.com/max/1374/1*EMhHR_g4UWEYpxsVWdpKdA.png">
<meta property="og:image" content="http://example.com/2022/10/26/%E5%8F%8C%E9%98%B6%E6%AE%B5%E7%89%A9%E4%BD%93%E6%A3%80%E6%B5%8B/Fast_RCNN.png">
<meta property="og:image" content="http://example.com/2022/10/26/%E5%8F%8C%E9%98%B6%E6%AE%B5%E7%89%A9%E4%BD%93%E6%A3%80%E6%B5%8B/Faster_RCNN.png">
<meta property="og:image" content="http://example.com/2022/10/26/%E5%8F%8C%E9%98%B6%E6%AE%B5%E7%89%A9%E4%BD%93%E6%A3%80%E6%B5%8B/FPN.png">
<meta property="og:image" content="https://production-media.paperswithcode.com/methods/new_teaser_TMZlD2J.jpg">
<meta property="og:image" content="http://example.com/2022/10/26/%E5%8F%8C%E9%98%B6%E6%AE%B5%E7%89%A9%E4%BD%93%E6%A3%80%E6%B5%8B/R-FCN_originpaper.png">
<meta property="og:image" content="http://example.com/2022/10/26/%E5%8F%8C%E9%98%B6%E6%AE%B5%E7%89%A9%E4%BD%93%E6%A3%80%E6%B5%8B/Position-sensitive_score_map.png">
<meta property="article:published_time" content="2022-10-26T04:52:27.000Z">
<meta property="article:modified_time" content="2022-10-31T04:15:20.444Z">
<meta property="article:author" content="Scofield">
<meta name="twitter:card" content="summary">
<meta name="twitter:image" content="http://example.com/2022/10/26/%E5%8F%8C%E9%98%B6%E6%AE%B5%E7%89%A9%E4%BD%93%E6%A3%80%E6%B5%8B/RCNN.png">


<link rel="canonical" href="http://example.com/2022/10/26/%E5%8F%8C%E9%98%B6%E6%AE%B5%E7%89%A9%E4%BD%93%E6%A3%80%E6%B5%8B/">



<script class="next-config" data-name="page" type="application/json">{"sidebar":"","isHome":false,"isPost":true,"lang":"en","comments":true,"permalink":"http://example.com/2022/10/26/%E5%8F%8C%E9%98%B6%E6%AE%B5%E7%89%A9%E4%BD%93%E6%A3%80%E6%B5%8B/","path":"2022/10/26/双阶段物体检测/","title":"双阶段物体检测"}</script>

<script class="next-config" data-name="calendar" type="application/json">""</script>
<title>双阶段物体检测 | Scofield</title>
  






  <noscript>
    <link rel="stylesheet" href="/css/noscript.css">
  </noscript>
</head>

<body itemscope itemtype="http://schema.org/WebPage" class="use-motion">
  <div class="headband"></div>

  <main class="main">
    <header class="header" itemscope itemtype="http://schema.org/WPHeader">
      <div class="header-inner"><div class="site-brand-container">
  <div class="site-nav-toggle">
    <div class="toggle" aria-label="Toggle navigation bar" role="button">
        <span class="toggle-line"></span>
        <span class="toggle-line"></span>
        <span class="toggle-line"></span>
    </div>
  </div>

  <div class="site-meta">

    <a href="/" class="brand" rel="start">
      <i class="logo-line"></i>
      <p class="site-title">Scofield</p>
      <i class="logo-line"></i>
    </a>
  </div>

  <div class="site-nav-right">
    <div class="toggle popup-trigger">
    </div>
  </div>
</div>



<nav class="site-nav">
  <ul class="main-menu menu"><li class="menu-item menu-item-home"><a href="/" rel="section"><i class="fa fa-home fa-fw"></i>Home</a></li><li class="menu-item menu-item-about"><a href="/about/" rel="section"><i class="fa fa-user fa-fw"></i>About</a></li><li class="menu-item menu-item-tags"><a href="/tags/" rel="section"><i class="fa fa-tag fa-fw"></i>Tags</a></li><li class="menu-item menu-item-categories"><a href="/categories/" rel="section"><i class="fa fa-th fa-fw"></i>Categories</a></li><li class="menu-item menu-item-archives"><a href="/archives/" rel="section"><i class="fa fa-archive fa-fw"></i>Archives</a></li>
  </ul>
</nav>




</div>
        
  
  <div class="toggle sidebar-toggle" role="button">
    <span class="toggle-line"></span>
    <span class="toggle-line"></span>
    <span class="toggle-line"></span>
  </div>

  <aside class="sidebar">

    <div class="sidebar-inner sidebar-nav-active sidebar-toc-active">
      <ul class="sidebar-nav">
        <li class="sidebar-nav-toc">
          Table of Contents
        </li>
        <li class="sidebar-nav-overview">
          Overview
        </li>
      </ul>

      <div class="sidebar-panel-container">
        <!--noindex-->
        <div class="post-toc-wrap sidebar-panel">
            <div class="post-toc animated"><ol class="nav"><li class="nav-item nav-level-1"><a class="nav-link" href="#%E6%A6%82%E8%BF%B0"><span class="nav-number">1.</span> <span class="nav-text">概述</span></a></li><li class="nav-item nav-level-1"><a class="nav-link" href="#r-cnna"><span class="nav-number">2.</span> <span class="nav-text">R-CNN</span></a><ol class="nav-child"><li class="nav-item nav-level-2"><a class="nav-link" href="#%E6%B5%8B%E8%AF%95%E8%BF%87%E7%A8%8B"><span class="nav-number">2.1.</span> <span class="nav-text">测试过程</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#%E8%AE%AD%E7%BB%83%E8%BF%87%E7%A8%8B"><span class="nav-number">2.2.</span> <span class="nav-text">训练过程</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#rcnn%E7%BC%BA%E7%82%B9"><span class="nav-number">2.3.</span> <span class="nav-text">RCNN缺点</span></a></li></ol></li><li class="nav-item nav-level-1"><a class="nav-link" href="#spp-net"><span class="nav-number">3.</span> <span class="nav-text">SPP-net</span></a></li><li class="nav-item nav-level-1"><a class="nav-link" href="#fast-r-cnn"><span class="nav-number">4.</span> <span class="nav-text">Fast R-CNN</span></a><ol class="nav-child"><li class="nav-item nav-level-2"><a class="nav-link" href="#%E6%94%B9%E8%BF%9B"><span class="nav-number">4.1.</span> <span class="nav-text">改进</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#%E5%85%B6%E4%BB%96%E7%BB%93%E8%AE%BA"><span class="nav-number">4.2.</span> <span class="nav-text">其他结论</span></a></li></ol></li><li class="nav-item nav-level-1"><a class="nav-link" href="#faster-r-cnn"><span class="nav-number">5.</span> <span class="nav-text">Faster R-CNN</span></a><ol class="nav-child"><li class="nav-item nav-level-2"><a class="nav-link" href="#%E6%94%B9%E8%BF%9B-1"><span class="nav-number">5.1.</span> <span class="nav-text">改进</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#rpn"><span class="nav-number">5.2.</span> <span class="nav-text">RPN</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#rpn%E4%B8%AD%E6%AD%A3%E8%B4%9F%E6%A0%B7%E6%9C%AC%E7%9A%84%E8%AE%BE%E7%BD%AE"><span class="nav-number">5.2.1.</span> <span class="nav-text">RPN中正负样本的设置</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#%E6%8D%9F%E5%A4%B1%E5%87%BD%E6%95%B0"><span class="nav-number">5.2.2.</span> <span class="nav-text">损失函数</span></a></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#%E8%AE%AD%E7%BB%83%E8%BF%87%E7%A8%8B-1"><span class="nav-number">5.3.</span> <span class="nav-text">训练过程</span></a></li></ol></li><li class="nav-item nav-level-1"><a class="nav-link" href="#fpn"><span class="nav-number">6.</span> <span class="nav-text">FPN</span></a><ol class="nav-child"><li class="nav-item nav-level-2"><a class="nav-link" href="#%E6%A6%82%E8%BF%B0-1"><span class="nav-number">6.1.</span> <span class="nav-text">概述</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#fpn%E5%9C%A8faster-rcnn%E4%B8%AD%E7%9A%84%E9%83%A8%E7%BD%B2%E7%BB%86%E8%8A%82"><span class="nav-number">6.2.</span> <span class="nav-text">fpn在faster rcnn中的部署细节</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#pytorch%E5%AE%9E%E7%8E%B0"><span class="nav-number">6.3.</span> <span class="nav-text">pytorch实现</span></a></li></ol></li><li class="nav-item nav-level-1"><a class="nav-link" href="#r-fcn"><span class="nav-number">7.</span> <span class="nav-text">R-FCN</span></a><ol class="nav-child"><li class="nav-item nav-level-2"><a class="nav-link" href="#%E6%A6%82%E8%BF%B0-2"><span class="nav-number">7.1.</span> <span class="nav-text">概述</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#position-sensitive-score-map%E7%9A%84%E8%A7%A3%E9%87%8A"><span class="nav-number">7.2.</span> <span class="nav-text">Position-sensitive score map的解释</span></a></li></ol></li><li class="nav-item nav-level-1"><a class="nav-link" href="#%E5%8F%82%E8%80%83"><span class="nav-number">8.</span> <span class="nav-text">参考</span></a></li></ol></div>
        </div>
        <!--/noindex-->

        <div class="site-overview-wrap sidebar-panel">
          <div class="site-author site-overview-item animated" itemprop="author" itemscope itemtype="http://schema.org/Person">
    <img class="site-author-image" itemprop="image" alt="Scofield"
      src="/images/avatar.png">
  <p class="site-author-name" itemprop="name">Scofield</p>
  <div class="site-description" itemprop="description"></div>
</div>
<div class="site-state-wrap site-overview-item animated">
  <nav class="site-state">
      <div class="site-state-item site-state-posts">
        <a href="/archives/">
          <span class="site-state-item-count">15</span>
          <span class="site-state-item-name">posts</span>
        </a>
      </div>
      <div class="site-state-item site-state-categories">
          <a href="/categories/">
        <span class="site-state-item-count">8</span>
        <span class="site-state-item-name">categories</span></a>
      </div>
  </nav>
</div>
  <div class="links-of-author site-overview-item animated">
      <span class="links-of-author-item">
        <a href="https://github.com/just-do-it-ai" title="GitHub → https:&#x2F;&#x2F;github.com&#x2F;just-do-it-ai" rel="noopener" target="_blank"><i class="fab fa-github fa-fw"></i>GitHub</a>
      </span>
      <span class="links-of-author-item">
        <a href="mailto:xluo2583@gmail.com" title="E-Mail → mailto:xluo2583@gmail.com" rel="noopener" target="_blank"><i class="fa fa-envelope fa-fw"></i>E-Mail</a>
      </span>
      <span class="links-of-author-item">
        <a href="/images/wechat.jpg" title="WeChat → &#x2F;images&#x2F;wechat.jpg"><i class="fa fa-weixin fa-fw"></i>WeChat</a>
      </span>
  </div>



        </div>
      </div>
    </div>
  </aside>
  <div class="sidebar-dimmer"></div>


    </header>

    
  <div class="back-to-top" role="button" aria-label="Back to top">
    <i class="fa fa-arrow-up"></i>
    <span>0%</span>
  </div>

<noscript>
  <div class="noscript-warning">Theme NexT works best with JavaScript enabled</div>
</noscript>


    <div class="main-inner post posts-expand">


  


<div class="post-block">
  
  

  <article itemscope itemtype="http://schema.org/Article" class="post-content" lang="en">
    <link itemprop="mainEntityOfPage" href="http://example.com/2022/10/26/%E5%8F%8C%E9%98%B6%E6%AE%B5%E7%89%A9%E4%BD%93%E6%A3%80%E6%B5%8B/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.png">
      <meta itemprop="name" content="Scofield">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Scofield">
      <meta itemprop="description" content="">
    </span>

    <span hidden itemprop="post" itemscope itemtype="http://schema.org/CreativeWork">
      <meta itemprop="name" content="双阶段物体检测 | Scofield">
      <meta itemprop="description" content="">
    </span>
      <header class="post-header">
        <h1 class="post-title" itemprop="name headline">
          双阶段物体检测
        </h1>

        <div class="post-meta-container">
          <div class="post-meta">
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-calendar"></i>
      </span>
      <span class="post-meta-item-text">Posted on</span>

      <time title="Created: 2022-10-26 12:52:27" itemprop="dateCreated datePublished" datetime="2022-10-26T12:52:27+08:00">2022-10-26</time>
    </span>
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-calendar-check"></i>
      </span>
      <span class="post-meta-item-text">Edited on</span>
      <time title="Modified: 2022-10-31 12:15:20" itemprop="dateModified" datetime="2022-10-31T12:15:20+08:00">2022-10-31</time>
    </span>
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-folder"></i>
      </span>
      <span class="post-meta-item-text">In</span>
        <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
          <a href="/categories/%E8%AE%A1%E7%AE%97%E6%9C%BA%E8%A7%86%E8%A7%89/" itemprop="url" rel="index"><span itemprop="name">计算机视觉</span></a>
        </span>
          , 
        <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
          <a href="/categories/%E8%AE%A1%E7%AE%97%E6%9C%BA%E8%A7%86%E8%A7%89/%E7%89%A9%E4%BD%93%E6%A3%80%E6%B5%8B/" itemprop="url" rel="index"><span itemprop="name">物体检测</span></a>
        </span>
    </span>

  
</div>

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">
        <h1 id="概述">概述</h1>
<p>有一个独立模块来生成区域建议的网络被称为两阶段检测器。<span id="more"></span> 由于这些网络有两个单独的步骤，它们通常需要更长的时间来生成建议框，具有复杂的架构，缺乏全局上下文信息。 单级检测器使用密集采样在单个镜头中( in a single shot)对语义对象进行分类和定位。具有更简单的结构和实时检测能力。</p>
<h1 id="r-cnna"><a target="_blank" rel="noopener" href="https://www.mihaileric.com/posts/object-detection-with-rcnn/">R-CNN</a></h1>
<img src="/2022/10/26/%E5%8F%8C%E9%98%B6%E6%AE%B5%E7%89%A9%E4%BD%93%E6%A3%80%E6%B5%8B/RCNN.png" class="" title="This is an example image">
<h2 id="测试过程">测试过程<br></h2>
<ul>
<li>R-CNN使用选择性搜素方法选出2000个候选框。</li>
<li>每个候选框通过训练好的CNN特征提取网络生成4096维的特征向量</li>
<li>特征向量通过一组线性支持向量机(简称SVM)运行，其中每个SVM被设计为对单个对象类进行分类。换句话说，一个经过训练的支持向量机用来探测船只，另一个用来探测鹦鹉，等等。每个SVM为给定的类输出一个分数，表明候选框包含该类的可能性。R-CNN将用与得分最高的支持向量机(SVM)对应的类为区域候选框的标签，如下标签为狗。 <img src="https://www.mihaileric.com/static/vector_through_svm_classifiers-cc139d6728db3205c0297a8f04c010ee-6fd10.png" /></li>
<li>在R-CNN使用类特定的支持向量机对每个区域候选框进行评分后，使用类特定的边界框回归器(岭回归)对建议候选框进行细化产生新的预测框。</li>
</ul>
<h2 id="训练过程">训练过程</h2>
<p>训练包含3个独立的模块：一是CNN(AlexNet)的微调；二是SVM的分类器训练；三是检测器回归框的训练。<br></p>
<ul>
<li>CNN先在大型通用数据集上进行训练，此时训练的标签是图像级的(也就是一张图片对应一个类别标签)，类别是1000类；再在特定领域的数据集上进行微调，此时的分类变成N+1类，对于PASCAL VOC数据集N为20。每个minibatch使用32个正样本(over all classes)，96个负样本。IoU大于0.5时为正样本，否则为负样本。</li>
<li>继续使用特定领域的数据集训练SVM分类器，此时正负样本的定义略有不同。将真值框作为正样本，将IoU小于0.3的检测框作为负样本。这个值是经验值，设置的不同模型的表现也会跟着变化。</li>
<li>回归器的训练使用的数据集是<span class="math inline">\((P, G)\)</span>对，<span class="math inline">\(G\)</span>是真值框，<span class="math inline">\(P\)</span>是与真值框IoU大于0.6的检测框。</li>
</ul>
<blockquote>
<p>作者说CNN一开始使用的正负样本定义和SVM相同(即只将真值框作为正样本)，但实验结果不如上面的差异化的正负样本定义。之所以设置0.5作为CNN网络的正负样本阈值，是因为阈值条件宽松可以扩充正样本数据量，不容易过拟合。具体见原论文7.2章第2段。<br></p>
</blockquote>
<blockquote>
<p>使用SVM进行分类训练而不直接使用softmax层也是因为性能下降。其原因可能是： 一是CNN特征提取使用0.5作为阈值区分正负样本，这个条件比较宽松，如果直接接softmax分类效果不好；二是CNN负样本是随机选择，而非"hard negtive"。在fast rcnn中，使用softmax的结果又比SVM好，原因作者没有分析，但可能和文章使用的minibatch sampling方法不同有关，具体见fast rcnn原论文5.4。 具体见原论文3.3.3第2段，7.2章第3段。<br></p>
</blockquote>
<h2 id="rcnn缺点">RCNN缺点<br></h2>
<ul>
<li>时间复杂度高，因为每张图像需要对2000个区域提议进行分类。</li>
<li>采用了选择性搜索算法。选择性搜索时间长，并且由于是一种固定算法，不能学习，导致可能产生坏的候选框。</li>
<li>特征提取和分类检测分开，不是端到端训练。</li>
</ul>
<h1 id="spp-net">SPP-net</h1>
<p>(Spatial Pyramid Pooling, SPP) <img src="/2022/10/26/%E5%8F%8C%E9%98%B6%E6%AE%B5%E7%89%A9%E4%BD%93%E6%A3%80%E6%B5%8B/SPP.png" class="" title="This is an example image"><br></p>
<p><strong>问题</strong>：<br> CNN的图像输入需要通过裁剪(crop)或者扭曲(warp)的方式得到固定尺寸的输入。<br> <strong>发现</strong>：<br> CNN网络中只有全连接层要求固定尺寸的输入。<br> <strong>解决方法</strong>：<br> 设计了SPP层，SPP就是对特征图或者感兴趣区域进行不同层级的池化，然后将池化结果拼接得到固定尺寸的特征向量。<br> <img src="https://miro.medium.com/max/1374/1*EMhHR_g4UWEYpxsVWdpKdA.png" /> 无论特征图或者感兴趣区域的尺寸大小如何都可以通过SPP层得到固定尺寸的特征向量。<br> <strong>作用</strong>：<br> 空间金字塔池化层可用来处理任意大小或纵横比的图像。<br> <strong>物体检测领域的贡献</strong>：<br> SPP在物体检测中的主要贡献是在于通过共享卷积计算提升了RCNN模型速度。<br> <strong>弊端</strong>:<br> 为简单起见，其微调固定了卷积层，只训练了分类头，这会导致准确度下降。fast rcnn中认为之所以SPP不微调所有层是因为SPP层反向传播效率太低，效率太低是因为每个batch训练样本(roi)来自不同的图像，每个batch采样128个正负样本，这128个样本来自不同的图像。具体见fat rcnn2.3<br></p>
<p><a target="_blank" rel="noopener" href="https://github.com/yifanjiang97/sppnet-pytorch">代码网址</a> <figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># spp层的实现</span></span><br><span class="line"><span class="keyword">import</span> math</span><br><span class="line"><span class="keyword">def</span> <span class="title function_">spatial_pyramid_pool</span>(<span class="params">self,previous_conv, num_sample, previous_conv_size, out_pool_size</span>):</span><br><span class="line">    <span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="string">    returns: a tensor vector with shape [1 x n] is the concentration of multi-level pooling</span></span><br><span class="line"><span class="string">    &#x27;&#x27;&#x27;</span>    </span><br><span class="line">    <span class="comment"># print(previous_conv.size())</span></span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(<span class="built_in">len</span>(out_pool_size)):</span><br><span class="line">        <span class="comment"># print(previous_conv_size)</span></span><br><span class="line">        h_wid = <span class="built_in">int</span>(math.ceil(previous_conv_size[<span class="number">0</span>] / out_pool_size[i]))</span><br><span class="line">        w_wid = <span class="built_in">int</span>(math.ceil(previous_conv_size[<span class="number">1</span>] / out_pool_size[i]))</span><br><span class="line">        h_pad = (h_wid*out_pool_size[i] - previous_conv_size[<span class="number">0</span>] + <span class="number">1</span>)/<span class="number">2</span></span><br><span class="line">        w_pad = (w_wid*out_pool_size[i] - previous_conv_size[<span class="number">1</span>] + <span class="number">1</span>)/<span class="number">2</span></span><br><span class="line">        maxpool = nn.MaxPool2d((h_wid, w_wid), stride=(h_wid, w_wid), padding=(h_pad, w_pad))</span><br><span class="line">        x = maxpool(previous_conv)</span><br><span class="line">        <span class="keyword">if</span>(i == <span class="number">0</span>):</span><br><span class="line">            spp = x.view(num_sample,-<span class="number">1</span>)</span><br><span class="line">            <span class="comment"># print(&quot;spp size:&quot;,spp.size())</span></span><br><span class="line">        <span class="keyword">else</span>:</span><br><span class="line">            <span class="comment"># print(&quot;size:&quot;,spp.size())</span></span><br><span class="line">            spp = torch.cat((spp,x.view(num_sample,-<span class="number">1</span>)), <span class="number">1</span>)</span><br><span class="line">    <span class="keyword">return</span> spp</span><br></pre></td></tr></table></figure></p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> torch</span><br><span class="line"><span class="keyword">import</span> torch.nn <span class="keyword">as</span> nn</span><br><span class="line"><span class="keyword">from</span> torch.nn <span class="keyword">import</span> init</span><br><span class="line"><span class="keyword">import</span> functools</span><br><span class="line"><span class="keyword">from</span> torch.autograd <span class="keyword">import</span> Variable</span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">import</span> torch.nn.functional <span class="keyword">as</span> F</span><br><span class="line"><span class="keyword">from</span> spp_layer <span class="keyword">import</span> spatial_pyramid_pool</span><br><span class="line"><span class="keyword">class</span> <span class="title class_">SPP_NET</span>(nn.Module):</span><br><span class="line">    <span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="string">    A CNN model which adds spp layer so that we can input multi-size tensor</span></span><br><span class="line"><span class="string">    &#x27;&#x27;&#x27;</span></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self, opt, input_nc, ndf=<span class="number">64</span>,  gpu_ids=[]</span>):</span><br><span class="line">        <span class="built_in">super</span>(SPP_NET, self).__init__()</span><br><span class="line">        self.gpu_ids = gpu_ids</span><br><span class="line">        self.output_num = [<span class="number">4</span>,<span class="number">2</span>,<span class="number">1</span>]</span><br><span class="line">        </span><br><span class="line">        self.conv1 = nn.Conv2d(input_nc, ndf, <span class="number">4</span>, <span class="number">2</span>, <span class="number">1</span>, bias=<span class="literal">False</span>)</span><br><span class="line">        </span><br><span class="line">        self.conv2 = nn.Conv2d(ndf, ndf * <span class="number">2</span>, <span class="number">4</span>, <span class="number">1</span>, <span class="number">1</span>, bias=<span class="literal">False</span>)</span><br><span class="line">        self.BN1 = nn.BatchNorm2d(ndf * <span class="number">2</span>)</span><br><span class="line"></span><br><span class="line">        self.conv3 = nn.Conv2d(ndf * <span class="number">2</span>, ndf * <span class="number">4</span>, <span class="number">4</span>, <span class="number">1</span>, <span class="number">1</span>, bias=<span class="literal">False</span>)</span><br><span class="line">        self.BN2 = nn.BatchNorm2d(ndf * <span class="number">4</span>)</span><br><span class="line"></span><br><span class="line">        self.conv4 = nn.Conv2d(ndf * <span class="number">4</span>, ndf * <span class="number">8</span>, <span class="number">4</span>, <span class="number">1</span>, <span class="number">1</span>, bias=<span class="literal">False</span>)</span><br><span class="line">        self.BN3 = nn.BatchNorm2d(ndf * <span class="number">8</span>)</span><br><span class="line"></span><br><span class="line">        self.conv5 = nn.Conv2d(ndf * <span class="number">8</span>, <span class="number">64</span>, <span class="number">4</span>, <span class="number">1</span>, <span class="number">0</span>, bias=<span class="literal">False</span>)</span><br><span class="line">        self.fc1 = nn.Linear(<span class="number">10752</span>,<span class="number">4096</span>)</span><br><span class="line">        self.fc2 = nn.Linear(<span class="number">4096</span>,<span class="number">1000</span>)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">forward</span>(<span class="params">self,x</span>):</span><br><span class="line">        x = self.conv1(x)</span><br><span class="line">        x = self.LReLU1(x)</span><br><span class="line"></span><br><span class="line">        x = self.conv2(x)</span><br><span class="line">        x = F.leaky_relu(self.BN1(x))</span><br><span class="line"></span><br><span class="line">        x = self.conv3(x)</span><br><span class="line">        x = F.leaky_relu(self.BN2(x))</span><br><span class="line">        </span><br><span class="line">        x = self.conv4(x)</span><br><span class="line">        <span class="comment"># x = F.leaky_relu(self.BN3(x))</span></span><br><span class="line">        <span class="comment"># x = self.conv5(x)</span></span><br><span class="line">        spp = spatial_pyramid_pool(x,<span class="number">1</span>,[<span class="built_in">int</span>(x.size(<span class="number">2</span>)),<span class="built_in">int</span>(x.size(<span class="number">3</span>))],self.output_num)</span><br><span class="line">        <span class="comment"># print(spp.size())</span></span><br><span class="line">        fc1 = self.fc1(spp)</span><br><span class="line">        fc2 = self.fc2(fc1)</span><br><span class="line">        s = nn.Sigmoid()</span><br><span class="line">        output = s(fc2)</span><br><span class="line">        <span class="keyword">return</span> output</span><br></pre></td></tr></table></figure>
<h1 id="fast-r-cnn">Fast R-CNN</h1>
<img src="/2022/10/26/%E5%8F%8C%E9%98%B6%E6%AE%B5%E7%89%A9%E4%BD%93%E6%A3%80%E6%B5%8B/Fast_RCNN.png" class="" title="This is an example image">
<p><br></p>
<h2 id="改进">改进<br></h2>
<ul>
<li>使用RoI Pooling层替换了SPP层。RoI Pooling层就是single-level SPP层</li>
<li>采用多任务学习方法，而不是RCNN中的分阶段训练(softmax分类阶段，SVMs分类阶段，检测框回归阶段)，实现了端到端的训练；同时改变了检测框回归的损失函数，该损失函数相对RCNN中的L2损失函数具有更强的鲁棒性。<br></li>
</ul>
<blockquote>
<p>fast rcnn中的检测框回归损失函数： <span class="math display">\[l=\sum_{i\in\{x,y,w,h\}}smooth_{L_1}(t_i-v_i)\]</span> <span class="math display">\[
\begin{equation}
smooth_{L_1}(x)= \begin{cases}
0.5x^2, &amp; if |x|&lt;1 \\
|x|-0.5, &amp; otherwise\\
\end{cases}
\end{equation}
\]</span> 选择L2损失对于比较大的误差的惩罚很高。 采用稍微缓和一点绝对损失函数（L1损失）f(x)=|x|，它是随着误差线性增长，而不是平方增长。但这个函数在0点处导数不存在，因此可能会影响收敛。解决办法是分段函数，在0点附近使用平方函数使得它更加平滑。因此被称为平滑L1损失函数<br></p>
</blockquote>
<ul>
<li>mini-batch sampling方法优化，像RCNN一样仍采样128个样本数据(RoI)，但不同的是这128个样本数据仅来自于2张图片，也就是每张图片有64个样本数据。25%为正样本，检测框与真值框的IoU大于0.5为正样本，大于0.1小于0.5为负样本，低阈值0.1此处起到类似难例挖掘的作用。</li>
</ul>
<blockquote>
<p>SPPnet和RCNN的128个样本来自128张图片。而fast rcnn的128个数据样本来自2张图片，这样的好处在于，网络在前向过程和反向传播时可以共享计算。速度提升64倍。</p>
</blockquote>
<h2 id="其他结论">其他结论</h2>
<ul>
<li>微调卷积层能带来mAP的提升，但是从conv2 1往上微调带来的mAP提升比从conv3 1往上微调带来的mAP提升只高0.3个points，时间却是conv3 1的1.3倍。</li>
<li>多尺度方法会带来小幅度mAP的提升，但是会带来大量的计算时间开销。</li>
<li>更多的训练数据对mAP有2-3个points的提升。</li>
<li>更密集的候选框并不会带来mAP的提升，甚至会对模型性能有伤害。</li>
</ul>
<h1 id="faster-r-cnn">Faster R-CNN</h1>
<img src="/2022/10/26/%E5%8F%8C%E9%98%B6%E6%AE%B5%E7%89%A9%E4%BD%93%E6%A3%80%E6%B5%8B/Faster_RCNN.png" class="" title="This is an example image">
<p><br></p>
<h2 id="改进-1">改进</h2>
<ul>
<li>设计了一个非常小的卷积网络RPN来替代选择性搜索算法生成候选框，加快了网络速度。</li>
<li>针对候选框尺度和横纵比，提出了anchor box的概念。在最后一层特征图的每个像素位置，设置3种尺度(128<em>128，256</em>256，512*512)和3种比例(1:1,1:2,2:1)共9种组合的anchor box。</li>
</ul>
<blockquote>
<p>为了网络习得尺度不变性，之前的网络做法有两种，一是缩放图像和特征图，fast rcnn中图像金字塔有5种尺度{480, 576, 688, 864, 1200}；二是使用多种不同大小的卷积核。具体参见原论文3.1.1</p>
</blockquote>
<h2 id="rpn">RPN</h2>
<h3 id="rpn中正负样本的设置">RPN中正负样本的设置</h3>
<p>正样本有2种情况：<br></p>
<ul>
<li>和ground truth具有最高交并比的anchor。</li>
<li>和ground truth交并比超过0.7的anchor。</li>
</ul>
<p>负样本是和ground truth交并比小于0.3的anchor。 每个mini batch采样256个样本，不同于论文fast rcnn，这256个样本全部来自同一张图片，正负样本的比例设置成1：1，如果正样本的数量不够128，则使用负样本补齐。</p>
<h3 id="损失函数">损失函数</h3>
<p>损失函数和fast rcnn类似。 分类只有正负2个类别，所以分类是一个二值交叉熵损失。 回归使用的是smooth L1损失。</p>
<h2 id="训练过程-1">训练过程</h2>
<p>可以把faster rcnn看作两个独立的网络rpn和fast rcnn的组合，两个网络都有相同的backbone(vgg)。rpn和fast rcnn如果独立训练会以不同的方式改变backbone(vgg)，为了能够共享backbone，需要一种策略去训练网络。作者提供了3种方法，而faster rcnn使用的是以下这种方法更新网络参数,训练过程有4步：<br></p>
<p><strong>四步交替迭代训练:</strong><br> 1. 使用imagenet预训练模型初始化rpn的backbone(vgg)，微调backbone和rpn网络。<br> 2. 使用第一步提供的proposal，相当于用proposal替代了选择性搜素算法提供的检测框，然后按照原fast rcnn的方法去训练。<br></p>
<blockquote>
<p>目前两个网络还没有共享backbone(vgg)，是两个独立的网络。<br></p>
</blockquote>
<ol start="3" type="1">
<li>固定第二步训练得到backbone参数，训练rpn，此时两个网络共享了backbone。<br></li>
<li>继续固定backbone的参数，训练fast rcnn。</li>
</ol>
<blockquote>
<p>虽然原始论文中用四步交替迭代训练。然而现在github上开源的实现大多是采用近似联合训练(Approximate joint training)，完成端到端训练。</p>
</blockquote>
<h1 id="fpn">FPN</h1>
<img src="/2022/10/26/%E5%8F%8C%E9%98%B6%E6%AE%B5%E7%89%A9%E4%BD%93%E6%A3%80%E6%B5%8B/FPN.png" class="" title="Feature Pyramid Networks">
<p><br></p>
<h2 id="概述-1">概述</h2>
<p><strong>问题:</strong><br> 特征金字塔是识别系统检测不同尺度物体的基本组成部分。但最近的深度学习对象检测器已经避免了金字塔表示，部分原因是它们需要大量的计算和内存。<br> <strong>解决方法:</strong><br> 利用深度卷积网络固有的多尺度、金字塔层次结构，以边际额外成本(marginal extra cost:只能说造词能力很强，边际额外成本没有定义，应该指的是虽然计算开销增加了，但是以高效率的方式增加的，相对于其他方法增加的计算开销很小)构建特征金字塔。开发了一种具有横向连接的自顶向下架构，用于构建各种尺度的高级语义特征图。这种架构被称为特征金字塔网络。<br> <strong>fpn与其他方法比较：</strong> <img src="https://production-media.paperswithcode.com/methods/new_teaser_TMZlD2J.jpg" /></p>
<h2 id="fpn在faster-rcnn中的部署细节">fpn在faster rcnn中的部署细节</h2>
<p><strong>对于rpn：</strong><br> 因为头部(rpnhead,也就是一个3x3卷积后跟两个1x1卷积分别对应着分类和回归)在所有金字塔层级的所有像素位置上密集滑动，在特定的层级上没有必要有多尺度的锚框(anchor)。相反，我们将单一尺度的锚框分配到每个层级，当然每个层级的锚框还是有3种横纵比。那么，如果有5个层级，则会有15种锚框。<span class="math inline">\(\{32^2, 64^2, 128^2, 256^2, 512^2\}\)</span>，尺度为32的对应着底层的特征图<span class="math inline">\(p_2\)</span>。<br> <strong>对于fast rcnn：</strong><br> Fast R-CNN是一个基于区域的对象检测器，它使用感兴趣区域(RoI)提取特征。Fast R-CNN最常在单尺度特征图上执行。要将它与FPN一起使用，我们需要将不同尺度的roi分配到金字塔级别。分配公式如下： <span class="math display">\[k = \lfloor k_0 + log_2(\sqrt{wh}/224)\rfloor\]</span> 224是imagenet预训练网络常用的尺度。Fast R-CNN使用<span class="math inline">\(C_4\)</span>作为单尺度特征映射，因此将<span class="math inline">\(k_0\)</span>设为4。w和h是感兴趣区域在输入图像上的宽和高。<br></p>
<blockquote>
<p>fpn中给从底向上路径的特征图取名为<span class="math inline">\(\{C_2,C_3,C_4,C_5,C_6\}\)</span>，从顶向下路径的特征图取名为<span class="math inline">\(\{P_2,P_3,P_4,P_5,P_6\}\)</span>。<span class="math inline">\(C_2\)</span>和<span class="math inline">\(P_2\)</span>对应着不同路径下相同分辨率特征图且是最底层特征图。</p>
</blockquote>
<h2 id="pytorch实现">pytorch实现</h2>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br><span class="line">110</span><br><span class="line">111</span><br><span class="line">112</span><br><span class="line">113</span><br><span class="line">114</span><br><span class="line">115</span><br><span class="line">116</span><br><span class="line">117</span><br><span class="line">118</span><br><span class="line">119</span><br><span class="line">120</span><br><span class="line">121</span><br><span class="line">122</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> collections <span class="keyword">import</span> OrderedDict</span><br><span class="line"><span class="keyword">from</span> typing <span class="keyword">import</span> <span class="type">Tuple</span>, <span class="type">List</span>, <span class="type">Dict</span>, <span class="type">Optional</span></span><br><span class="line"><span class="keyword">import</span> torch.nn.functional <span class="keyword">as</span> F</span><br><span class="line"><span class="keyword">from</span> torch <span class="keyword">import</span> nn, Tensor</span><br><span class="line"><span class="keyword">from</span> ..utils <span class="keyword">import</span> _log_api_usage_once</span><br><span class="line"></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">FeaturePyramidNetwork</span>(nn.Module):</span><br><span class="line">    <span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">    The feature maps are currently supposed to be in increasing depth</span></span><br><span class="line"><span class="string">    order.</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">    The input to the model is expected to be an OrderedDict[Tensor], containing the feature maps on top of which the FPN will be added.</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">    Args:</span></span><br><span class="line"><span class="string">        in_channels_list (list[int]): number of channels for each feature map that</span></span><br><span class="line"><span class="string">            is passed to the module</span></span><br><span class="line"><span class="string">        out_channels (int): number of channels of the FPN representation</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">    Examples::</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">        &gt;&gt;&gt; m = torchvision.ops.FeaturePyramidNetwork([10, 20, 30], 5)</span></span><br><span class="line"><span class="string">        &gt;&gt;&gt; # get some dummy data</span></span><br><span class="line"><span class="string">        &gt;&gt;&gt; x = OrderedDict()</span></span><br><span class="line"><span class="string">        &gt;&gt;&gt; x[&#x27;feat0&#x27;] = torch.rand(1, 10, 64, 64)</span></span><br><span class="line"><span class="string">        &gt;&gt;&gt; x[&#x27;feat2&#x27;] = torch.rand(1, 20, 16, 16)</span></span><br><span class="line"><span class="string">        &gt;&gt;&gt; x[&#x27;feat3&#x27;] = torch.rand(1, 30, 8, 8)</span></span><br><span class="line"><span class="string">        &gt;&gt;&gt; # compute the FPN on top of x</span></span><br><span class="line"><span class="string">        &gt;&gt;&gt; output = m(x)</span></span><br><span class="line"><span class="string">        &gt;&gt;&gt; print([(k, v.shape) for k, v in output.items()])</span></span><br><span class="line"><span class="string">        &gt;&gt;&gt; # returns</span></span><br><span class="line"><span class="string">        &gt;&gt;&gt;   [(&#x27;feat0&#x27;, torch.Size([1, 5, 64, 64])),</span></span><br><span class="line"><span class="string">        &gt;&gt;&gt;    (&#x27;feat2&#x27;, torch.Size([1, 5, 16, 16])),</span></span><br><span class="line"><span class="string">        &gt;&gt;&gt;    (&#x27;feat3&#x27;, torch.Size([1, 5, 8, 8]))]</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">    &quot;&quot;&quot;</span></span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params"></span></span><br><span class="line"><span class="params">        self,</span></span><br><span class="line"><span class="params">        in_channels_list: <span class="type">List</span>[<span class="built_in">int</span>],</span></span><br><span class="line"><span class="params">        out_channels: <span class="built_in">int</span>,</span></span><br><span class="line"><span class="params">        extra_blocks: <span class="type">Optional</span>[ExtraFPNBlock] = <span class="literal">None</span>,</span></span><br><span class="line"><span class="params">    </span>):</span><br><span class="line">        <span class="built_in">super</span>().__init__()</span><br><span class="line">        _log_api_usage_once(self)</span><br><span class="line">        self.inner_blocks = nn.ModuleList()</span><br><span class="line">        self.layer_blocks = nn.ModuleList()</span><br><span class="line">        <span class="keyword">for</span> in_channels <span class="keyword">in</span> in_channels_list:</span><br><span class="line">            <span class="keyword">if</span> in_channels == <span class="number">0</span>:</span><br><span class="line">                <span class="keyword">raise</span> ValueError(<span class="string">&quot;in_channels=0 is currently not supported&quot;</span>)</span><br><span class="line">            <span class="comment">#1x1卷积改变输入通道数</span></span><br><span class="line">            inner_block_module = nn.Conv2d(in_channels, out_channels, <span class="number">1</span>)</span><br><span class="line">            layer_block_module = nn.Conv2d(out_channels, out_channels, <span class="number">3</span>, padding=<span class="number">1</span>)</span><br><span class="line">            self.inner_blocks.append(inner_block_module)</span><br><span class="line">            self.layer_blocks.append(layer_block_module)</span><br><span class="line"></span><br><span class="line">        <span class="comment"># 权重初始化</span></span><br><span class="line">        <span class="keyword">for</span> m <span class="keyword">in</span> self.modules():</span><br><span class="line">            <span class="keyword">if</span> <span class="built_in">isinstance</span>(m, nn.Conv2d):</span><br><span class="line">                nn.init.kaiming_uniform_(m.weight, a=<span class="number">1</span>)</span><br><span class="line">                nn.init.constant_(m.bias, <span class="number">0</span>)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">get_result_from_inner_blocks</span>(<span class="params">self, x: Tensor, idx: <span class="built_in">int</span></span>) -&gt; Tensor:</span><br><span class="line"></span><br><span class="line">        num_blocks = <span class="built_in">len</span>(self.inner_blocks)</span><br><span class="line">        <span class="comment">#如果idx为-1，表示最后一层，加上num_block后变成正数的最后一层索引</span></span><br><span class="line">        <span class="keyword">if</span> idx &lt; <span class="number">0</span>:</span><br><span class="line">            idx += num_blocks</span><br><span class="line">        out = x</span><br><span class="line">        <span class="keyword">for</span> i, module <span class="keyword">in</span> <span class="built_in">enumerate</span>(self.inner_blocks):</span><br><span class="line">        <span class="comment">#找到对应层，进行1x1卷积，改变输入x的通道数</span></span><br><span class="line">            <span class="keyword">if</span> i == idx:</span><br><span class="line">                out = module(x)</span><br><span class="line">        <span class="keyword">return</span> out</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">get_result_from_layer_blocks</span>(<span class="params">self, x: Tensor, idx: <span class="built_in">int</span></span>) -&gt; Tensor:</span><br><span class="line">        num_blocks = <span class="built_in">len</span>(self.layer_blocks)</span><br><span class="line">        <span class="comment">#如果idx为-1，表示最后一层，加上num_block后变成正数的最后一层索引</span></span><br><span class="line">        <span class="keyword">if</span> idx &lt; <span class="number">0</span>:</span><br><span class="line">            idx += num_blocks</span><br><span class="line">        out = x</span><br><span class="line">        <span class="keyword">for</span> i, module <span class="keyword">in</span> <span class="built_in">enumerate</span>(self.layer_blocks):</span><br><span class="line">        <span class="comment">#找到对应层进行3x3卷积</span></span><br><span class="line">            <span class="keyword">if</span> i == idx:</span><br><span class="line">                out = module(x)</span><br><span class="line">        <span class="keyword">return</span> out</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">forward</span>(<span class="params">self, x: <span class="type">Dict</span>[<span class="built_in">str</span>, Tensor]</span>) -&gt; <span class="type">Dict</span>[<span class="built_in">str</span>, Tensor]:</span><br><span class="line">        <span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">        Computes the FPN for a set of feature maps.</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">        Args:</span></span><br><span class="line"><span class="string">            x (OrderedDict[Tensor]): feature maps for each feature level.</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">        Returns:</span></span><br><span class="line"><span class="string">            results (OrderedDict[Tensor]): feature maps after FPN layers.</span></span><br><span class="line"><span class="string">                They are ordered from highest resolution first.</span></span><br><span class="line"><span class="string">        &quot;&quot;&quot;</span></span><br><span class="line">        <span class="comment"># unpack OrderedDict into two lists for easier handling</span></span><br><span class="line">        names = <span class="built_in">list</span>(x.keys())</span><br><span class="line">        x = <span class="built_in">list</span>(x.values())</span><br><span class="line"></span><br><span class="line">        last_inner = self.get_result_from_inner_blocks(x[-<span class="number">1</span>], -<span class="number">1</span>)</span><br><span class="line">        results = []</span><br><span class="line">        results.append(self.get_result_from_layer_blocks(last_inner, -<span class="number">1</span>))</span><br><span class="line"></span><br><span class="line">        <span class="keyword">for</span> idx <span class="keyword">in</span> <span class="built_in">range</span>(<span class="built_in">len</span>(x) - <span class="number">2</span>, -<span class="number">1</span>, -<span class="number">1</span>):</span><br><span class="line">            <span class="comment">#特征层1x1卷积</span></span><br><span class="line">            inner_lateral = self.get_result_from_inner_blocks(x[idx], idx)</span><br><span class="line">            feat_shape = inner_lateral.shape[-<span class="number">2</span>:]</span><br><span class="line">            <span class="comment">#上采样2倍</span></span><br><span class="line">            inner_top_down = F.interpolate(last_inner, size=feat_shape, mode=<span class="string">&quot;nearest&quot;</span>)</span><br><span class="line">            last_inner = inner_lateral + inner_top_down</span><br><span class="line">            <span class="comment">#3x3卷积后，将高分辨率的特征图放在列表前面</span></span><br><span class="line">            results.insert(<span class="number">0</span>, self.get_result_from_layer_blocks(last_inner, idx))</span><br><span class="line"></span><br><span class="line">        <span class="comment"># make it back an OrderedDict</span></span><br><span class="line">        out = OrderedDict([(k, v) <span class="keyword">for</span> k, v <span class="keyword">in</span> <span class="built_in">zip</span>(names, results)])</span><br><span class="line"></span><br><span class="line">        <span class="keyword">return</span> out</span><br></pre></td></tr></table></figure>
<h1 id="r-fcn">R-FCN</h1>
<h2 id="概述-2">概述</h2>
<p><strong>问题</strong>：<br> rpn会提供几百个proposals，fast rcnn需要重复计算上百次，计算开销很大。<br> <strong>解决方案：</strong><br> 基于区域的全卷积网络(R-FCN)共享网络内几乎所有的计算。<br> 然而，卷积网络中的更深层次是平移不变的，这使得它们对定位任务无效。<br> 作者使用位置敏感评分图(position-sensitive score maps)来补救。<br> 这些敏感的评分图编码了前景目标的相对空间信息，汇集起来可以确定准确的定位。<br> <strong>具体实现：</strong><br> R-FCN检测器是四种卷积网络的组合。输入图像首先通过ResNet-101得到特征映射。中间输出(Conv4层)被传递到区域建议网络(RPN)来产生proposals，而最终输出通过卷积层进一步处理，并输入到分类器和回归器。分类层将创建的位置敏感映射与proposals相结合，生成预测，而回归网络输出边界框属性。<br> ResNet-101应用到R-FCN时会把最后的average pool和1000-d全连接层都去掉了，仅保留卷积层，再新加一个1x1x1024的卷积层用来降维（从2048维降到1024维），和一个很特殊的卷积来生成<span class="math inline">\(k^2\times (C+1)\)</span>维的Position-sensitive score map。其中的<span class="math inline">\(C\)</span>是要分类的类别数。<span class="math inline">\(k\)</span>是之后的ROI Pooling中对ROI区域要划分的小格数，比如论文中<span class="math inline">\(k=3\)</span>就是对ROI在长宽方向各三等分形成9个小区域。</p>
<img src="/2022/10/26/%E5%8F%8C%E9%98%B6%E6%AE%B5%E7%89%A9%E4%BD%93%E6%A3%80%E6%B5%8B/R-FCN_originpaper.png" class="" title="R-FCN_originpaper">
<p>最后一个特殊卷积输出Position-sensitive score map后，就要做ROI Pooling了，和Faster R-CNN中的ROI Pooling一样要对9个小区域分别进行pooling，要注意的是R-FCN中９个小区域并不是在所有<span class="math inline">\(k^2\times (C+1)\)</span>维度上都做pooling，每个小区域只会在对应的C+1个维度上作pooling，比如ROI左上角的区域就在前<span class="math inline">\(C+1\)</span>个维度上pooling，左中位置的区域就在<span class="math inline">\(C+2\)</span>到<span class="math inline">\(2C+2\)</span>间的维度上作pooling，以此类推。pooling后输出的是<span class="math inline">\(C+1\)</span>维度的<span class="math inline">\(k\times k\)</span>数据，每个维度上的<span class="math inline">\(k\times k\)</span>个数据再加到一起(vote过程)形成<span class="math inline">\(C+1\)</span>个单点数据，就代表了<span class="math inline">\(C+1\)</span>个类别的分类概率。<br> 对于目标定位的输出和上面的分类输出过程类似，只是维度不再是<span class="math inline">\(k^2\times (C+1)\)</span>，而是<span class="math inline">\(k^2\times 4\)</span>，表示９个小区域的<span class="math inline">\([dx,dy,dw,dh]\)</span> 4个偏移坐标。</p>
<h2 id="position-sensitive-score-map的解释">Position-sensitive score map的解释</h2>
<p>Position-sensitive score map的概念最早来自另一篇实例分割的<a target="_blank" rel="noopener" href="https://arxiv.org/pdf/1603.08678.pdf">论文</a>。<br> 中间的9张图对应Position-sensitive score map的9个维度的输出。 拿左上角的图说明：它的每一个点代表该点正好出现在目标左上角的得分，也可以理解是该点右下方正好是目标的概率。要注意的是：“目标左上角的概率”的概念并不局限于图中画的绿色框范围，而是整张图上的每一个点。<br> 同理其余8张图各自对应了目标正上侧、右上侧、左中侧、正中侧、右中侧、左下侧、正下侧、右下侧的得分。<br> 在训练时，一个ROI的9个小区域从每张图的对应区域去Pooling出一个结果，组成新的图，如果ROI刚好覆盖ground truth，这个新的区域就标记为前景(label=1)。 为什么每张图都能携带相对位置信息？因为从9张图中提取1~9号小方格时，每个小方格在每张图上的位置并不相同，而是在上下左右方向上有偏移，当组合出来的9宫格对应ground truth时，小方格1就对应了ground truth左上角的位置，小方格2对应了ground truth正上方的位置，依此类推，所以用这种9宫格训练目标时就有了相对目标位置的信息在里面。</p>
<img src="/2022/10/26/%E5%8F%8C%E9%98%B6%E6%AE%B5%E7%89%A9%E4%BD%93%E6%A3%80%E6%B5%8B/Position-sensitive_score_map.png" class="" title="Position-sensitive_score_map">
<h1 id="参考">参考</h1>

    </div>

    
    
    

    <footer class="post-footer">

        

          <div class="post-nav">
            <div class="post-nav-item">
                <a href="/2022/10/25/%E5%8D%95%E9%98%B6%E6%AE%B5%E7%89%A9%E4%BD%93%E6%A3%80%E6%B5%8B/" rel="prev" title="单阶段物体检测">
                  <i class="fa fa-chevron-left"></i> 单阶段物体检测
                </a>
            </div>
            <div class="post-nav-item">
            </div>
          </div>
    </footer>
  </article>
</div>






</div>
  </main>

  <footer class="footer">
    <div class="footer-inner">


<div class="copyright">
  &copy; 
  <span itemprop="copyrightYear">2022</span>
  <span class="with-love">
    <i class="fa fa-heart"></i>
  </span>
  <span class="author" itemprop="copyrightHolder">Scofield</span>
</div>
  <div class="powered-by">Powered by <a href="https://hexo.io/" rel="noopener" target="_blank">Hexo</a> & <a href="https://theme-next.js.org/muse/" rel="noopener" target="_blank">NexT.Muse</a>
  </div>

    </div>
  </footer>

  
  <script src="https://cdnjs.cloudflare.com/ajax/libs/animejs/3.2.1/anime.min.js" integrity="sha256-XL2inqUJaslATFnHdJOi9GfQ60on8Wx1C2H8DYiN1xY=" crossorigin="anonymous"></script>
<script src="/js/comments.js"></script><script src="/js/utils.js"></script><script src="/js/motion.js"></script><script src="/js/schemes/muse.js"></script><script src="/js/next-boot.js"></script>

  





  




  

  <script class="next-config" data-name="enableMath" type="application/json">true</script><script class="next-config" data-name="mathjax" type="application/json">{"enable":true,"tags":"none","js":{"url":"https://cdnjs.cloudflare.com/ajax/libs/mathjax/3.2.2/es5/tex-mml-chtml.js","integrity":"sha256-MASABpB4tYktI2Oitl4t+78w/lyA+D7b/s9GEP0JOGI="}}</script>
<script src="/js/third-party/math/mathjax.js"></script>



</body>
</html>
